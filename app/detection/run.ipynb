{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "57e4cad8ca6145b0ac02ede2c97d0c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb7cad58b74d4ea9981b72d739998373",
              "IPY_MODEL_d88505b2844c422cb0364634dfd57920"
            ],
            "layout": "IPY_MODEL_dcdae569061742a1894388e6dfdec9fd"
          }
        },
        "bb7cad58b74d4ea9981b72d739998373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89024a5752534d3fa229400aa528ba54",
            "placeholder": "​",
            "style": "IPY_MODEL_6a69db4ae5074a3883176c428b8a1f11",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "d88505b2844c422cb0364634dfd57920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e40e4c0d79bf4933927cba0781ee5f66",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19ed4e2c38fb4f90a823264e9eb7417b",
            "value": 1
          }
        },
        "dcdae569061742a1894388e6dfdec9fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89024a5752534d3fa229400aa528ba54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a69db4ae5074a3883176c428b8a1f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e40e4c0d79bf4933927cba0781ee5f66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19ed4e2c38fb4f90a823264e9eb7417b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pydicom -qU\n",
        "!pip3 install wandb -qU\n",
        "!pip3 install effdet -qU\n",
        "\n",
        "import wandb\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import random"
      ],
      "metadata": {
        "id": "RBgCpPIZG-d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enqdXWVgGiq5",
        "outputId": "52ed26c0-d3c4-4ed1-c329-c49b5bd9d3b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)  # set PYTHONHASHSEED env var at fixed value\n",
        "    random.seed(seed)  #set fixed value for python built-in pseudo-random generator\n",
        "    np.random.seed(seed) # for numpy pseudo-random generator\n",
        "    torch.manual_seed(seed) # pytorch (both CPU and CUDA)\n",
        "\n",
        "set_seed(2020)"
      ],
      "metadata": {
        "id": "9u652SjRt1OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_PCrkVJh0hl",
        "outputId": "a1859a08-3d97-4685-ddc3-6cfd3cd8806f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mioana-baciu4\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "wandb.login(key = \"8a625877a46f5b9236fa4719743bf8c17928ead7\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr-7iQuDh0hm",
        "outputId": "d57659e2-3403-4eb0-e7b8-a73abb1b1fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: smih9zqu\n",
            "Sweep URL: https://wandb.ai/ioana-baciu4/licenta/sweeps/smih9zqu\n"
          ]
        }
      ],
      "source": [
        "sweep_config: dict = {\n",
        "    \"project\": \"licenta\",\n",
        "    \"metric\":\n",
        "        {\"name\": \"loss\",\"goal\": \"minimize\"}\n",
        "    ,\n",
        "    \"method\": \"grid\", # grid/random\n",
        "     \"parameters\":\n",
        "    #     {\n",
        "    #     \"learning_rate\": {\n",
        "    #         \"values\": [1e-4, 1e-5, 1e-6]\n",
        "    #         },\n",
        "    #     \"number_of_epochs\": {\n",
        "    #         \"values\": [8,9,10]\n",
        "    #         },\n",
        "    #     },\n",
        "    None\n",
        "}\n",
        "parameters: dict = {\n",
        "    \"learning_rate\": {\n",
        "        \"values\": [1e-3, 1e-4, 1e-5]\n",
        "    },\n",
        "    \"number_of_epochs\": {\n",
        "        \"values\": [50,75,100]\n",
        "    }\n",
        "}\n",
        "sweep_config[\"parameters\"] = parameters\n",
        "sweep_id = wandb.sweep(sweep_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB2gVcYHh0hk",
        "outputId": "0e7ba7c4-439d-4957-bc8a-32ffda06ac4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘drive/MyDrive/Licenta/detection_checkpoints’: File exists\n"
          ]
        }
      ],
      "source": [
        "!cp drive/MyDrive/Licenta/duke_dbt_data.py .\n",
        "!cp drive/MyDrive/Licenta/sort_split_data.py .\n",
        "!mkdir drive/MyDrive/Licenta/detection_checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "from random import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.utils.data\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import v2\n",
        "from duke_dbt_data import dcmread_image, draw_box\n",
        "from sort_split_data import find_image_path\n",
        "from IPython.display import Image, display\n",
        "from skimage.io import imread\n",
        "import torchvision.transforms.functional as fn\n",
        "import albumentations as A\n",
        "\n",
        "\n",
        "def get_train_transforms():\n",
        "    return A.Compose([\n",
        "        # A.OneOf([\n",
        "        #     A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2,\n",
        "        #                          val_shift_limit=0.2, p=0.9),\n",
        "        #     A.RandomBrightnessContrast(brightness_limit=0.2,\n",
        "        #                                contrast_limit=0.2, p=0.9),\n",
        "        # ], p=0.9),\n",
        "        # A.ToGray(p=0.01),\n",
        "        # A.HorizontalFlip(p=0.5),\n",
        "        # A.VerticalFlip(p=0.5),\n",
        "    ],\n",
        "        p=1.0,\n",
        "        bbox_params=A.BboxParams(\n",
        "            format='pascal_voc',\n",
        "            min_area=0,\n",
        "            min_visibility=0,\n",
        "            label_fields=['labels'],\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def get_nth_file_name(directory, n):\n",
        "    return np.sort(np.array(os.listdir(directory)))[n]\n",
        "\n",
        "\n",
        "def extract_indices(batch, index, size, class_indices):\n",
        "    sampled_indices = np.random.choice(class_indices[index], size=size, replace=False)\n",
        "    batch.extend(sampled_indices.tolist())\n",
        "    indices = []\n",
        "    for sample in sampled_indices:\n",
        "        new_index = np.where(class_indices[index] == sample)\n",
        "        indices.append(int(new_index[0][0]))\n",
        "    indices = np.array(indices)\n",
        "    class_indices[index] = np.delete(class_indices[index], indices)\n",
        "\n",
        "\n",
        "def add_class(batch, index, amount, class_indices):\n",
        "    extract_indices(batch, index, amount, class_indices)\n",
        "\n",
        "\n",
        "class DetectionDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, base_folder, split_name, number_of_slices, batch_size,\n",
        "                 transfm=get_train_transforms(), threshold=None):\n",
        "        super().__init__()\n",
        "        self.transfm = transfm\n",
        "        self.base_folder = base_folder\n",
        "        self.batch_size = batch_size\n",
        "        self.number_of_slices = number_of_slices\n",
        "        self.threshold = threshold\n",
        "        self.images_file = os.path.join(self.base_folder, \"images/\")\n",
        "        self.label_file = os.path.join(self.base_folder, f\"labels/BCS-DBT labels-{split_name}.csv\")\n",
        "        self.data_paths = []\n",
        "        self.breastCancerData = pd.read_csv(os.path.join(self.base_folder, f\"BCS-DBT file-paths-{split_name}.csv\"))\n",
        "        self.breastCancerBoxes = pd.read_csv(os.path.join(self.base_folder,\n",
        "                                                          f\"bounding_boxes/BCS-DBT boxes-{split_name}.csv\"))\n",
        "        self.breastCancerLabel = pd.read_csv(self.label_file)\n",
        "        if threshold is None:\n",
        "            self.threshold = self.breastCancerBoxes.shape[0]\n",
        "        self.targets = []\n",
        "        self.mean = [0.485, 0.456, 0.406]\n",
        "        self.std = [0.229, 0.224, 0.225]\n",
        "        self.load_data()\n",
        "\n",
        "    def calculate_class_indices(self):\n",
        "        class_indices = {}\n",
        "        for class_label in range(2):\n",
        "            class_indices[class_label] = np.where(np.array(self.targets) == class_label+1)[0]\n",
        "        return class_indices\n",
        "\n",
        "    def load_image(self, path, file_name):\n",
        "        slices = np.zeros(shape=[3, 512, 512], dtype=np.float32)\n",
        "        slices[0] = imread(fname=os.path.join(path, file_name), as_gray=True)\n",
        "        slices[0] = slices[0] / 255.0  # Scale pixel values to [0, 1]\n",
        "        slices = torch.tensor(slices)\n",
        "        slices[1] = slices[0]\n",
        "        slices[2] = slices[0]\n",
        "        slices = fn.normalize(slices, mean=self.mean, std=self.std)\n",
        "        return slices\n",
        "\n",
        "    def load_data(self):\n",
        "        minimum = 104\n",
        "        for idx in range(0, self.threshold):\n",
        "            view_series = self.breastCancerBoxes.iloc[idx]\n",
        "            label = view_series[\"Class\"]\n",
        "            if label == 'benign':\n",
        "                label = 1\n",
        "            else:\n",
        "                label = 2\n",
        "            index_fisier = self.breastCancerData.index[\n",
        "                self.breastCancerData[\"PatientID\"] == view_series[\"PatientID\"]].tolist()[0]\n",
        "            image_path = find_image_path(self.breastCancerData.iloc[index_fisier])\n",
        "            shape = get_nth_file_name(image_path, 0)\n",
        "            slices = int(shape[1:shape.index(\",\")])\n",
        "            if slices < minimum:\n",
        "                minimum = slices\n",
        "            for i in range(self.number_of_slices):\n",
        "                self.targets.append(label)\n",
        "                if image_path[-1] == \"/\":\n",
        "                    self.data_paths.append(image_path + f\"{i}\")\n",
        "                else:\n",
        "                    self.data_paths.append(image_path + f\"/{i}\")\n",
        "\n",
        "        if self.batch_size == 1:\n",
        "            return\n",
        "\n",
        "        class_indices = self.calculate_class_indices()\n",
        "        batches = []\n",
        "        malign = len(class_indices[1]) - len(class_indices[0])\n",
        "        if malign > 0:\n",
        "            sampled_indices = np.random.choice(class_indices[1], size=malign, replace=False)\n",
        "            indices = []\n",
        "            for sample in sampled_indices:\n",
        "                index = np.where(class_indices[1] == sample)\n",
        "                indices.append(int(index[0][0]))\n",
        "            class_indices[1] = np.delete(class_indices[1], indices)\n",
        "            self.data_paths = np.delete(self.data_paths, sampled_indices)\n",
        "            self.targets = np.delete(self.targets, sampled_indices)\n",
        "            class_indices = self.calculate_class_indices()\n",
        "        benign = len(class_indices[0]) - len(class_indices[1])\n",
        "        if benign >  0:\n",
        "            sampled_indices = np.random.choice(class_indices[0], size=benign, replace=False)\n",
        "            indices = []\n",
        "            for sample in sampled_indices:\n",
        "                index = np.where(class_indices[0] == sample)\n",
        "                indices.append(int(index[0][0]))\n",
        "            class_indices[0] = np.delete(class_indices[0], indices)\n",
        "            self.data_paths = np.delete(self.data_paths, sampled_indices)\n",
        "            self.targets = np.delete(self.targets, sampled_indices)\n",
        "            class_indices = self.calculate_class_indices()\n",
        "        batches_number = len(self) // self.batch_size\n",
        "        if batches_number * self.batch_size != len(self):\n",
        "            batches_number = batches_number + 1\n",
        "        batch_number = 0\n",
        "        while batch_number < batches_number:\n",
        "            batch = []\n",
        "            add_class(batch, 1, min(self.batch_size // 2, len(class_indices[1])), class_indices)\n",
        "            add_class(batch, 0, min(self.batch_size // 2, len(class_indices[0])), class_indices)\n",
        "            np.random.shuffle(batch)\n",
        "            batches.extend(batch)\n",
        "            batch_number = batch_number + 1\n",
        "        self.data_paths = np.array(self.data_paths)\n",
        "        batches = np.array(batches)\n",
        "        self.data_paths = self.data_paths[batches]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_paths)\n",
        "\n",
        "    def scale_coordinates(self, index):\n",
        "        image_path = find_image_path(self.breastCancerData.iloc[index])\n",
        "        shape = get_nth_file_name(image_path, 0)\n",
        "        original_width = int(shape[shape.index(\",\") + 1:shape.rindex(\",\")])\n",
        "        original_height = int(shape[shape.rindex(\",\") + 1:shape.rindex(\")\")])\n",
        "\n",
        "        new_width = 512\n",
        "        new_height = 512\n",
        "\n",
        "        scale_width = new_width / original_width\n",
        "        scale_height = new_height / original_height\n",
        "\n",
        "        return scale_width, scale_height\n",
        "\n",
        "    def load_bounding_box(self, idx, index_fisier):\n",
        "        scaled_width, scaled_height = self.scale_coordinates(index_fisier)\n",
        "        x, y, width, height = self.breastCancerBoxes.iloc[idx][\"X\"], \\\n",
        "            self.breastCancerBoxes.iloc[idx][\"Y\"], \\\n",
        "            self.breastCancerBoxes.iloc[idx][\"Width\"], \\\n",
        "            self.breastCancerBoxes.iloc[idx][\"Height\"]\n",
        "        boxes = [x * scaled_height, y * scaled_width,\n",
        "                 (x + width) * scaled_height, (y + height) * scaled_width]\n",
        "        # boxes = np.array(boxes)\n",
        "        # boxes = boxes[np.array((1, 0, 3, 2))]\n",
        "        label = self.breastCancerBoxes.iloc[idx][\"Class\"]\n",
        "        if label == 'benign':\n",
        "            label = 1.\n",
        "        else:\n",
        "            label = 2.\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32).unsqueeze(dim=0)\n",
        "        label = torch.tensor(label).unsqueeze(dim=0)\n",
        "\n",
        "        target = {'bbox': boxes, 'cls': label}\n",
        "\n",
        "        return target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        slice_path = self.data_paths[index]\n",
        "        directory_path = slice_path[:slice_path.rindex(\"/\") + 1]\n",
        "        path_in_file = slice_path[len(self.base_folder) + 7:]\n",
        "        path_in_file = path_in_file[:path_in_file.rindex(\"/\") + 1] + \"1-1.dcm\"\n",
        "        file_name_1 = path_in_file[:path_in_file.rindex(\"NA\") - 1]\n",
        "        path_in_file = file_name_1 + path_in_file[path_in_file.rindex(\"NA\") + 2:]\n",
        "        index_fisier = self.breastCancerData.index[\n",
        "            self.breastCancerData[\"descriptive_path\"] == path_in_file].tolist()[0]\n",
        "        index_fisier_boxes = self.breastCancerBoxes.index[\n",
        "            self.breastCancerBoxes[\"PatientID\"] == self.breastCancerData.iloc[index_fisier][\"PatientID\"]].tolist()[0]\n",
        "        index_slice = slice_path[self.data_paths[index].rindex(\"/\") + 1]\n",
        "        file_name = get_nth_file_name(directory_path, int(index_slice) + 1)\n",
        "        image = self.load_image(directory_path, file_name)\n",
        "        bounding_box = self.load_bounding_box(index_fisier_boxes, index_fisier)\n",
        "\n",
        "        sample = self.transfm(**{\n",
        "            'image': np.array(image.permute(1, 2, 0)),\n",
        "            'bboxes': bounding_box['bbox'],\n",
        "            'labels': bounding_box['cls']\n",
        "        })\n",
        "        target = {}\n",
        "        image = torch.tensor(sample['image']).permute(2, 0, 1)\n",
        "        target['bbox'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
        "        target['bbox'][:, [0, 1, 2, 3]] = target['bbox'][:, [1, 0, 3, 2]]\n",
        "        target['bbox'] = target['bbox'].clone().detach()\n",
        "        target['bbox'] = target['bbox'].to(torch.float32).cpu()\n",
        "        target['cls'] = torch.stack(sample['labels']).cpu()  # <--- add this!\n",
        "        # = get_valid_transforms()(**sample)\n",
        "        return image.cpu(), target"
      ],
      "metadata": {
        "id": "m-6rNXsk29cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n"
      ],
      "metadata": {
        "id": "Q6e4j2D13SMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Fitter:\n",
        "\n",
        "    def __init__(self, model, config, sweep_config=None, device=\"cpu\", reload=None):\n",
        "        self.epoch = 0\n",
        "        self.config = config\n",
        "\n",
        "        self.base_dir = f'./{config.folder}'\n",
        "        if not os.path.exists(self.base_dir):\n",
        "            os.makedirs(self.base_dir)\n",
        "\n",
        "        # self.log_path = f'{self.base_dir}/log.txt'\n",
        "        self.best_summary_loss = 10 ** 5\n",
        "\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "\n",
        "        param_optimizer = list(self.model.named_parameters())\n",
        "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "        self.sweep_config = sweep_config\n",
        "        if sweep_config is not None:\n",
        "            run = wandb.init(config=sweep_config)\n",
        "            print(run)\n",
        "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=0.0001)\n",
        "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
        "\n",
        "        if reload is not None:\n",
        "            all_files = np.sort(np.array(os.listdir(self.base_dir)))\n",
        "            path = all_files[0]\n",
        "            self.load(os.path.join(self.base_dir,path))\n",
        "            for i in range(1, len(all_files)):\n",
        "                os.remove(os.path.join(self.base_dir, all_files[i]))\n",
        "\n",
        "\n",
        "    def fit(self, train_loader, validation_loader):\n",
        "        for e in range(self.config.n_epochs):\n",
        "            if self.config.verbose:\n",
        "                lr = self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "            summary_loss = self.train_one_epoch(train_loader)\n",
        "            # if self.config.step_scheduler:\n",
        "            #     self.scheduler.step(metrics=summary_loss.avg)\n",
        "\n",
        "            if summary_loss.avg<self.best_summary_loss:\n",
        "                path = f'{self.base_dir}/loss_{summary_loss.avg}_epoch_{self.epoch}.pth'\n",
        "                if len(str(int(summary_loss.avg))) != len(str(int(self.best_summary_loss))):\n",
        "                    all_files = os.listdir(self.base_dir)\n",
        "                    for file in all_files:\n",
        "                      os.remove(os.path.join(self.base_dir, file))\n",
        "                self.save(path)\n",
        "                self.best_summary_loss = summary_loss.avg\n",
        "\n",
        "            summary_loss = self.validation(validation_loader)\n",
        "            if self.config.validation_scheduler:\n",
        "                self.scheduler.step()\n",
        "\n",
        "            self.epoch += 1\n",
        "            if e%10 == 0:\n",
        "                all_files = np.sort(np.array(os.listdir(self.base_dir)))\n",
        "                path = all_files[0]\n",
        "                self.load(os.path.join(self.base_dir,path))\n",
        "                for i in range(1, len(all_files)):\n",
        "                    os.remove(os.path.join(self.base_dir, all_files[i]))\n",
        "\n",
        "    def validation(self, val_loader):\n",
        "        self.model.eval()\n",
        "        summary_loss = AverageMeter()\n",
        "        for data, targets in tqdm(val_loader):\n",
        "            with torch.no_grad():\n",
        "                images = torch.stack(data).cpu().to(self.device)\n",
        "                batch_size = images.shape[0]\n",
        "\n",
        "                transformed_dict = {'bbox': [], 'cls': [],\n",
        "                                    'img_size': [],\n",
        "                                    'img_scale': []}\n",
        "                for element in targets:\n",
        "                    for key, value in element.items():\n",
        "                        transformed_dict[key].append(value)\n",
        "                        transformed_dict['img_size'].append(torch.tensor((512, 512)).unsqueeze(dim=0))\n",
        "                        transformed_dict['img_scale'].append(torch.tensor(1).unsqueeze(dim=0))\n",
        "\n",
        "                transformed_dict['bbox'] = torch.cat(transformed_dict['bbox'], dim=0).cpu().to(self.device)\n",
        "                transformed_dict['cls'] = torch.cat(transformed_dict['cls'], dim=0).cpu().to(self.device)\n",
        "                transformed_dict['img_size'] = torch.cat(transformed_dict['img_size'], dim=0).cpu().to(self.device)\n",
        "                transformed_dict['img_scale'] = torch.cat(transformed_dict['img_scale'], dim=0).cpu().to(self.device)\n",
        "\n",
        "                output = self.model(images, transformed_dict)\n",
        "                loss = output[\"loss\"]\n",
        "                if self.sweep_config is not None:\n",
        "                    wandb.log({\"loss_test\": loss.item()})\n",
        "\n",
        "                summary_loss.update(loss.detach().item(), batch_size)\n",
        "\n",
        "        return summary_loss\n",
        "\n",
        "    def train_one_epoch(self, train_loader):\n",
        "        self.model.train()\n",
        "        summary_loss = AverageMeter()\n",
        "        for data, targets in tqdm(train_loader):\n",
        "            images = torch.stack(data).cpu().to(self.device)\n",
        "            # images = images.to(self.device).float()\n",
        "            batch_size = images.shape[0]\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            transformed_dict = {'bbox': [], 'cls': []}\n",
        "\n",
        "            for element in targets:\n",
        "                for key, value in element.items():\n",
        "                    transformed_dict[key].append(value)\n",
        "\n",
        "            transformed_dict['bbox'] = torch.cat(transformed_dict['bbox'], dim=0).cpu().to(self.device)\n",
        "            transformed_dict['cls'] = torch.cat(transformed_dict['cls'], dim=0).cpu().to(self.device)\n",
        "\n",
        "            loss = self.model(images, transformed_dict)[\"loss\"]\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            if self.config.step_scheduler:\n",
        "                self.scheduler.step()\n",
        "            summary_loss.update(loss.detach().item(), batch_size)\n",
        "\n",
        "            if self.sweep_config is not None:\n",
        "                wandb.log({\"loss\": loss.item()})\n",
        "\n",
        "\n",
        "        return summary_loss\n",
        "\n",
        "    def save(self, path):\n",
        "        self.model.eval()\n",
        "        torch.save({\n",
        "            'model_state_dict': self.model.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
        "            'best_summary_loss': self.best_summary_loss,\n",
        "            'epoch': self.epoch,\n",
        "        }, path)\n",
        "\n",
        "    def load(self, path):\n",
        "        checkpoint = torch.load(path)\n",
        "        self.model.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        self.best_summary_loss = checkpoint['best_summary_loss']\n",
        "        self.epoch = checkpoint['epoch'] + 1\n",
        "\n",
        "bs = 16\n",
        "\n",
        "train_dataset = DetectionDataset(base_folder=\"drive/MyDrive/Licenta/\", split_name=\"train\", number_of_slices=22,\n",
        "                                 batch_size=bs)\n",
        "test_dataset = DetectionDataset(base_folder=\"drive/MyDrive/Licenta/\", split_name=\"test\", number_of_slices=22,\n",
        "                                batch_size=bs)\n"
      ],
      "metadata": {
        "id": "92GrWarJ3Meo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class TrainGlobalConfig:\n",
        "    num_workers = 0\n",
        "    batch_size = 16\n",
        "    n_epochs = 50  # n_epochs = 40\n",
        "    lr = 0.0002\n",
        "\n",
        "    folder = 'drive/MyDrive/Licenta/detection_checkpoints'\n",
        "\n",
        "    # -------------------\n",
        "    verbose = True\n",
        "    verbose_step = 1\n",
        "    # -------------------\n",
        "\n",
        "    # --------------------\n",
        "    step_scheduler = True  # do scheduler.step after optimizer.step\n",
        "    validation_scheduler = False  # do scheduler.step after validation stage loss\n",
        "\n",
        "    #     SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n",
        "    #     scheduler_params = dict(\n",
        "    #         max_lr=0.001,\n",
        "    #         epochs=n_epochs,\n",
        "    #         steps_per_epoch=int(len(train_dataset) / batch_size),\n",
        "    #         pct_start=0.1,\n",
        "    #         anneal_strategy='cos',\n",
        "    #         final_div_factor=10**5\n",
        "    #     )\n",
        "\n",
        "    SchedulerClass = torch.optim.lr_scheduler.CosineAnnealingLR\n",
        "    scheduler_params = dict(\n",
        "        T_max=int(len(train_dataset)/batch_size*60),\n",
        "        eta_min=1e-6,\n",
        "    )\n"
      ],
      "metadata": {
        "id": "Iuiy9q1v3ZTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
        "from effdet import create_model_from_config\n",
        "from effdet.efficientdet import HeadNet\n",
        "from torch import nn\n",
        "import timm\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "\n",
        "def get_net():\n",
        "\n",
        "    config = get_efficientdet_config('tf_efficientdet_d0')\n",
        "\n",
        "    config.image_size = (512, 512)\n",
        "    config.norm_kwargs = dict(eps=.001, momentum=.01)\n",
        "\n",
        "    net = create_model_from_config(config=config, bench_task='train', num_classes=2, pretrained=True, bench_labeler = True)\n",
        "\n",
        "    # net = EfficientDet(config, pretrained_backbone=False)\n",
        "    # checkpoint = torch.load('drive/MyDrive/Licenta/weights/efficientdet-d0_1.pth')\n",
        "    # net.load_state_dict(checkpoint, strict=False)\n",
        "\n",
        "    # net.reset_head(num_classes=config.num_classes)\n",
        "    # net.class_net = HeadNet(config, num_outputs=config.num_classes)\n",
        "\n",
        "    # return DetBenchTrain(net, config)\n",
        "\n",
        "    return net\n",
        "\n",
        "\n",
        "net = get_net()\n",
        "\n",
        "\n",
        "def run_training(sweep_config=None, reload=None):\n",
        "    # device = torch.device('cuda:0')\n",
        "    # net.to(device)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=bs,\n",
        "        num_workers=0,\n",
        "        collate_fn=collate_fn,\n",
        "    )\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=bs,\n",
        "        num_workers=0,\n",
        "        collate_fn=collate_fn,\n",
        "    )\n",
        "\n",
        "    fitter = Fitter(model=net, config=TrainGlobalConfig, reload=reload, sweep_config=sweep_config)\n",
        "    fitter.fit(train_loader, val_loader)\n"
      ],
      "metadata": {
        "id": "zbwKRTXS3UkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_training(sweep_config)\n",
        "# for i in range(4):\n",
        "#     run_training(sweep_config, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "57e4cad8ca6145b0ac02ede2c97d0c08",
            "bb7cad58b74d4ea9981b72d739998373",
            "d88505b2844c422cb0364634dfd57920",
            "dcdae569061742a1894388e6dfdec9fd",
            "89024a5752534d3fa229400aa528ba54",
            "6a69db4ae5074a3883176c428b8a1f11",
            "e40e4c0d79bf4933927cba0781ee5f66",
            "19ed4e2c38fb4f90a823264e9eb7417b"
          ]
        },
        "id": "wSOZ3t6JrsMA",
        "outputId": "980ed3b3-7424-4d0d-d8fc-18aba4bca01c"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:21i6g8nw) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57e4cad8ca6145b0ac02ede2c97d0c08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>███▇▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▄▄▄▄▄▃▃▃▃▂▃▂▁▂▁▁▂▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.75532</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lemon-bee-36</strong> at: <a href='https://wandb.ai/ioana-baciu4/uncategorized/runs/21i6g8nw' target=\"_blank\">https://wandb.ai/ioana-baciu4/uncategorized/runs/21i6g8nw</a><br/> View project at: <a href='https://wandb.ai/ioana-baciu4/uncategorized' target=\"_blank\">https://wandb.ai/ioana-baciu4/uncategorized</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240427_065207-21i6g8nw/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:21i6g8nw). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240427_070952-afb9mt0q</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ioana-baciu4/uncategorized/runs/afb9mt0q' target=\"_blank\">happy-lake-37</a></strong> to <a href='https://wandb.ai/ioana-baciu4/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ioana-baciu4/uncategorized' target=\"_blank\">https://wandb.ai/ioana-baciu4/uncategorized</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ioana-baciu4/uncategorized/runs/afb9mt0q' target=\"_blank\">https://wandb.ai/ioana-baciu4/uncategorized/runs/afb9mt0q</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<wandb.sdk.wandb_run.Run object at 0x791aa5f2d4e0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 88/88 [12:21<00:00,  8.42s/it]\n",
            "100%|██████████| 14/14 [01:02<00:00,  4.45s/it]\n",
            "100%|██████████| 88/88 [12:32<00:00,  8.55s/it]\n",
            "100%|██████████| 14/14 [00:32<00:00,  2.30s/it]\n",
            "100%|██████████| 88/88 [12:27<00:00,  8.49s/it]\n",
            "100%|██████████| 14/14 [00:30<00:00,  2.19s/it]\n",
            "100%|██████████| 88/88 [12:21<00:00,  8.43s/it]\n",
            "100%|██████████| 14/14 [00:33<00:00,  2.40s/it]\n",
            "100%|██████████| 88/88 [12:00<00:00,  8.19s/it]\n",
            "100%|██████████| 14/14 [00:32<00:00,  2.32s/it]\n",
            "100%|██████████| 88/88 [11:54<00:00,  8.12s/it]\n",
            "100%|██████████| 14/14 [00:31<00:00,  2.22s/it]\n",
            "100%|██████████| 88/88 [11:52<00:00,  8.10s/it]\n",
            "100%|██████████| 14/14 [00:30<00:00,  2.21s/it]\n",
            "100%|██████████| 88/88 [11:52<00:00,  8.10s/it]\n",
            "100%|██████████| 14/14 [00:31<00:00,  2.24s/it]\n",
            "100%|██████████| 88/88 [11:50<00:00,  8.07s/it]\n",
            "100%|██████████| 14/14 [00:32<00:00,  2.30s/it]\n",
            "100%|██████████| 88/88 [11:51<00:00,  8.08s/it]\n",
            "100%|██████████| 14/14 [00:32<00:00,  2.31s/it]\n",
            "  0%|          | 0/88 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0025d7695d92>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# for i in range(4):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     run_training(sweep_config, True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-b3eda0f9d6f4>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(sweep_config, reload)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mfitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrainGlobalConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msweep_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mfitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-2da47d62ea20>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, validation_loader)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0msummary_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;31m# if self.config.step_scheduler:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m#     self.scheduler.step(metrics=summary_loss.avg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-2da47d62ea20>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mtransformed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cls'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cls'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/effdet/bench.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, target)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mclass_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_labeler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# target should contain pre-computed anchor labels if labeler not present in bench\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/effdet/efficientdet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0mx_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    258\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stage_out_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                     \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/_efficientnet_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_pw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_dw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/layers/norm_act.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         x = F.batch_norm(\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2482\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}