{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T12:35:00.699270500Z",
     "start_time": "2024-03-23T12:34:55.429358300Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.utils.data\n",
    "import seaborn as sns\n",
    "# import wandb\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn as nn\n",
    "from dataclasses import dataclass\n",
    "#from train import train_with_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-23T12:35:00.714274100Z",
     "start_time": "2024-03-23T12:35:00.704273100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu' if torch.cuda.is_available() else 'cuda')\n",
    "device = 'cpu'\n",
    "print(device)\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-23T12:35:01.330781Z",
     "start_time": "2024-03-23T12:35:00.716275800Z"
    }
   },
   "outputs": [],
   "source": [
    "from classification_dataset import MyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-23T12:35:01.347785300Z",
     "start_time": "2024-03-23T12:35:01.333781900Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip3 install wandb -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-23T12:35:01.377798100Z",
     "start_time": "2024-03-23T12:35:01.349788Z"
    }
   },
   "outputs": [],
   "source": [
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-23T12:35:01.441805Z",
     "start_time": "2024-03-23T12:35:01.362789100Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(base_folder=\"data/\", split_name=\"train\")\n",
    "test_dataset = MyDataset(base_folder=\"data/\", split_name=\"test\")\n",
    "\n",
    "bs = 10\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, num_workers=0, shuffle=True,\n",
    "                                              generator=torch.Generator(device=device))\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, num_workers=4, shuffle=True,\n",
    "                                             generator=torch.Generator(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-23T12:35:01.458810100Z",
     "start_time": "2024-03-23T12:35:01.445806300Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class InputParameters:\n",
    "    model: nn.Module\n",
    "    optimizer: torch.optim.Optimizer\n",
    "    scheduler: torch.optim.lr_scheduler.ExponentialLR\n",
    "def save_checkpoint(model_input, optimizer_input, scheduler_input, filename):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    input_parameters = InputParameters(model_input, optimizer_input, scheduler_input)\n",
    "    torch.save(input_parameters, filename)\n",
    "def load_checkpoint(filename):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    input_parameters = torch.load(filename)\n",
    "    return input_parameters.model, input_parameters.optimizer, input_parameters.scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-23T12:35:01.479814300Z",
     "start_time": "2024-03-23T12:35:01.458810100Z"
    }
   },
   "outputs": [],
   "source": [
    "#CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-23T12:35:01.492819100Z",
     "start_time": "2024-03-23T12:35:01.476813900Z"
    }
   },
   "outputs": [],
   "source": [
    "sweep_config: dict = {\n",
    "    \"project\": \"licenta\",\n",
    "    \"metric\":\n",
    "        {\"name\": \"loss\",\"goal\": \"minimize\"}\n",
    "    ,\n",
    "    \"method\": \"grid\", # grid/random\n",
    "     \"parameters\":\n",
    "    #     {\n",
    "    #     \"learning_rate\": {\n",
    "    #         \"values\": [1e-4, 1e-5, 1e-6]\n",
    "    #         },\n",
    "    #     \"number_of_epochs\": {\n",
    "    #         \"values\": [8,9,10]\n",
    "    #         },\n",
    "    #     },\n",
    "    None\n",
    "}\n",
    "parameters: dict = {\n",
    "    \"learning_rate\": {\n",
    "        \"values\": [1e-4, 1e-5, 1e-6]\n",
    "    },\n",
    "    \"number_of_epochs\": {\n",
    "        \"values\": [50,75,100]\n",
    "    },\n",
    "    \"batch_sizes\": {\n",
    "        \"values\": [10, 12, 15],\n",
    "    }\n",
    "}\n",
    "sweep_config[\"parameters\"] = parameters\n",
    "#sweep_id = wandb.sweep(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-23T12:35:01.521824800Z",
     "start_time": "2024-03-23T12:35:01.491816400Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(loader, model_input, optimizer_input, loss_function, scheduler_input):\n",
    "  for data, targets in tqdm(loader):\n",
    "    data, targets = data.to(device), targets.to(device)\n",
    "    optimizer_input.zero_grad()\n",
    "    predictions = model_input(data)\n",
    "    loss = loss_function(predictions[0], targets)\n",
    "\n",
    "    print(f\"Loss: {loss}\")\n",
    "    print(f\"Predicted: {predictions}\")\n",
    "    print(f\"Real class: {targets}\")\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_input.step()\n",
    "\n",
    "    #wandb.log({\"loss\": loss.item()})\n",
    "  #scheduler_input.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-23T12:35:04.515503400Z",
     "start_time": "2024-03-23T12:35:01.516837700Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "\n",
    "\n",
    "def get_accuracy(real_target: Tensor, predicted_target: Tensor):\n",
    "    # noinspection PyTypeChecker\n",
    "    correctly_predicted = torch.sum(real_target == predicted_target).item()\n",
    "    all_targets = real_target.numel()\n",
    "    return correctly_predicted / all_targets\n",
    "\n",
    "\n",
    "def get_precision(real_target: Tensor, predicted_target: Tensor):\n",
    "    # noinspection PyTypeChecker\n",
    "    all_positive_predicted = torch.sum(predicted_target == 2).item() + torch.sum(predicted_target == 3).item()\n",
    "    # noinspection PyTypeChecker\n",
    "    true_positive_targets = torch.sum(\n",
    "        (real_target == predicted_target) &\n",
    "        (real_target == 2)).item() + torch.sum(\n",
    "        (real_target == predicted_target) &\n",
    "        (real_target == 3)).item()\n",
    "    precision = true_positive_targets / max(all_positive_predicted, 1)\n",
    "    return precision\n",
    "\n",
    "\n",
    "def get_recall(real_target: Tensor, predicted_target: Tensor):\n",
    "    # noinspection PyTypeChecker\n",
    "    all_positive_targets = torch.sum(real_target == 2).item() + torch.sum(real_target == 3).item()\n",
    "    # noinspection PyTypeChecker\n",
    "    true_positive_targets = torch.sum(\n",
    "        (real_target == predicted_target) &\n",
    "        (real_target == 2)).item() + torch.sum(\n",
    "        (real_target == predicted_target) &\n",
    "        (real_target == 3)).item()\n",
    "    recall = true_positive_targets / max(all_positive_targets, 1)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def get_confusion_matrix(real_target: Tensor, predicted_target: Tensor):\n",
    "    confusion_matrix = np.empty((4, 4), dtype=np.uint16)\n",
    "    actionable_predicted_values, benign_predicted_values, \\\n",
    "        cancer_predicted_values, normal_predicted_values = \\\n",
    "        get_predicted_classes_for_all_classes(predicted_target, real_target)\n",
    "    for i in range(0, 4):\n",
    "        set_confusion_matrix_values(actionable_predicted_values, benign_predicted_values, cancer_predicted_values,\n",
    "                                    confusion_matrix, i, normal_predicted_values)\n",
    "    return confusion_matrix\n",
    "\n",
    "\n",
    "def set_confusion_matrix_values(actionable_predicted_values, benign_predicted_values, cancer_predicted_values,\n",
    "                                confusion_matrix, i, normal_predicted_values):\n",
    "    # noinspection PyTypeChecker\n",
    "    confusion_matrix[0][i] = torch.sum(normal_predicted_values == i).item()\n",
    "    # noinspection PyTypeChecker\n",
    "    confusion_matrix[1][i] = torch.sum(actionable_predicted_values == i).item()\n",
    "    # noinspection PyTypeChecker\n",
    "    confusion_matrix[2][i] = torch.sum(benign_predicted_values == i).item()\n",
    "    # noinspection PyTypeChecker\n",
    "    confusion_matrix[3][i] = torch.sum(cancer_predicted_values == i).item()\n",
    "\n",
    "\n",
    "def get_predicted_classes_for_all_classes(predicted_target, real_target):\n",
    "    normal_predicted_values = get_predicted_class_for_normal_class(predicted_target, real_target)\n",
    "    actionable_predicted_values = get_predicted_class_for_actionable_class(predicted_target, real_target)\n",
    "    benign_predicted_values = get_predicted_class_for_benign_class(predicted_target, real_target)\n",
    "    cancer_predicted_values = get_predicted_class_for_malign_class(predicted_target, real_target)\n",
    "    return actionable_predicted_values, benign_predicted_values, cancer_predicted_values, normal_predicted_values\n",
    "\n",
    "\n",
    "def get_predicted_class_for_malign_class(predicted_target, real_target):\n",
    "    cancer_real_indexes = (real_target == 3).nonzero()\n",
    "    cancer_predicted_values = predicted_target[cancer_real_indexes]\n",
    "    return cancer_predicted_values\n",
    "\n",
    "\n",
    "def get_predicted_class_for_benign_class(predicted_target, real_target):\n",
    "    benign_real_indexes = (real_target == 2).nonzero()\n",
    "    benign_predicted_values = predicted_target[benign_real_indexes]\n",
    "    return benign_predicted_values\n",
    "\n",
    "\n",
    "def get_predicted_class_for_actionable_class(predicted_target, real_target):\n",
    "    actionable_real_indexes = (real_target == 1).nonzero()\n",
    "    actionable_predicted_values = predicted_target[actionable_real_indexes]\n",
    "    return actionable_predicted_values\n",
    "\n",
    "\n",
    "def get_predicted_class_for_normal_class(predicted_target, real_target):\n",
    "    normal_real_indexes = (real_target == 0).nonzero()\n",
    "    normal_predicted_values = predicted_target[normal_real_indexes]\n",
    "    return normal_predicted_values\n",
    "\n",
    "def check_metrics(loader, model_aux):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_predicted_classes = torch.tensor([]).to(device)\n",
    "        all_real_classes = torch.tensor([]).to(device)\n",
    "        for data, targets in tqdm(loader):\n",
    "            data, real_class = data.to(device), targets.to(device).argmax(dim=1)\n",
    "            predicted_class = model_aux(data)[0].to(device).argmax(dim=1)\n",
    "\n",
    "            all_predicted_classes = torch.cat((all_predicted_classes, predicted_class))\n",
    "            all_real_classes = torch.cat((all_real_classes, real_class))\n",
    "\n",
    "            accuracy = get_accuracy(all_real_classes, all_predicted_classes)\n",
    "            precision = get_precision(all_real_classes, all_predicted_classes)\n",
    "            recall = get_recall(all_real_classes, all_predicted_classes)\n",
    "            confusion_matrix = get_confusion_matrix(all_real_classes, all_predicted_classes)\n",
    "    return accuracy, precision, recall, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-23T12:35:04.529874400Z",
     "start_time": "2024-03-23T12:35:04.519504400Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_with_metrics(model_to_train, optimizer_to_train, scheduler_to_train):\n",
    "    #run = wandb.init(config=sweep_config)\n",
    "    loss_function = nn.CrossEntropyLoss(torch.tensor((1, 1, 2, 2)))\n",
    "    #learning_rate = wandb.config.learning_rate\n",
    "    #number_of_epochs = wandb.config.number_of_epochs\n",
    "    number_of_epochs = 50\n",
    "    for epoch in range(number_of_epochs):\n",
    "        model_to_train.train()\n",
    "        print(f\"=> Training epoch: {epoch+1}\")\n",
    "        train_one_epoch(train_data_loader, model_to_train, optimizer_to_train, loss_function, scheduler_to_train)\n",
    "        print(\"=> Finished training...\")\n",
    "        model_to_train.eval()\n",
    "        print(\"=> Calculating metrics...\")\n",
    "        accuracy, precision, recall, confusion_matrix = check_metrics(test_data_loader, model_to_train)\n",
    "    #wandb.log({\"accuracy\": accuracy, \"precision\": precision})\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        save_checkpoint(model_to_train, optimizer_to_train, scheduler_to_train, f\"./checkpoints/acc_{epoch}.pth\")\n",
    "        # plt.figure(figsize=(7, 5))\n",
    "        # sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g',\n",
    "        #         xticklabels=['normal', 'actionable', 'benign', 'malign'],\n",
    "        #         yticklabels=['normal', 'actionable', 'benign', 'malign'])\n",
    "        # plt.xlabel('Predicted labels')\n",
    "        # plt.ylabel('True labels')\n",
    "        # plt.title('Confusion Matrix')\n",
    "        # plt.show()\n",
    "    #run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-23T12:42:48.536287200Z",
     "start_time": "2024-03-23T12:35:04.530874100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Training epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.670336127281189\n",
      "Predicted: (tensor([[0.2307, 0.2319, 0.2832, 0.2543],\n",
      "        [0.2556, 0.2252, 0.2748, 0.2445],\n",
      "        [0.2697, 0.2344, 0.2676, 0.2284],\n",
      "        [0.2605, 0.2216, 0.2720, 0.2460],\n",
      "        [0.2606, 0.2176, 0.2809, 0.2409],\n",
      "        [0.2588, 0.2275, 0.2816, 0.2321],\n",
      "        [0.2618, 0.2270, 0.2940, 0.2173],\n",
      "        [0.2544, 0.2429, 0.2825, 0.2203],\n",
      "        [0.2561, 0.2268, 0.2724, 0.2447],\n",
      "        [0.2768, 0.2398, 0.2682, 0.2152]], grad_fn=<SoftmaxBackward0>), tensor([[-0.0194, -0.0468, -0.0224, -0.0089],\n",
      "        [-0.0940,  0.0869, -0.0932,  0.0372],\n",
      "        [ 0.0583,  0.0672, -0.0948, -0.0077],\n",
      "        [-0.0184, -0.1071, -0.0219, -0.1266],\n",
      "        [-0.0139, -0.1322, -0.0863,  0.0297],\n",
      "        [-0.0166, -0.1935,  0.0553,  0.0755],\n",
      "        [-0.0138, -0.1023, -0.1150, -0.0160],\n",
      "        [ 0.1515, -0.1018, -0.0647,  0.0496],\n",
      "        [-0.0166, -0.0080, -0.0404,  0.1155],\n",
      "        [ 0.2398, -0.1878, -0.0703,  0.0416]], grad_fn=<AddmmBackward0>), tensor([[-0.0527,  0.0546,  0.1032, -0.0737],\n",
      "        [-0.0167,  0.0621, -0.1176, -0.0854],\n",
      "        [-0.0350, -0.1301, -0.1457, -0.0676],\n",
      "        [ 0.0781, -0.0539, -0.0334, -0.2235],\n",
      "        [ 0.0311,  0.0103, -0.1118, -0.0771],\n",
      "        [ 0.2030,  0.0848,  0.0595, -0.0198],\n",
      "        [-0.0270,  0.0756,  0.0151, -0.1306],\n",
      "        [ 0.0183,  0.0811,  0.0362, -0.0365],\n",
      "        [-0.0157,  0.1407, -0.0248,  0.1374],\n",
      "        [-0.2409, -0.0475, -0.0412, -0.0343]], grad_fn=<AddmmBackward0>))\n",
      "Real class: tensor([[0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/57 [04:13<3:56:09, 253.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.654123306274414\n",
      "Predicted: (tensor([[0.2505, 0.2340, 0.2718, 0.2436],\n",
      "        [0.2474, 0.2294, 0.2743, 0.2489],\n",
      "        [0.2806, 0.2034, 0.2783, 0.2377],\n",
      "        [0.2512, 0.2419, 0.2782, 0.2287],\n",
      "        [0.2673, 0.2166, 0.2830, 0.2331],\n",
      "        [0.2804, 0.2247, 0.2700, 0.2249],\n",
      "        [0.2595, 0.2323, 0.2713, 0.2370],\n",
      "        [0.2809, 0.2210, 0.2839, 0.2143],\n",
      "        [0.2459, 0.2301, 0.2767, 0.2472],\n",
      "        [0.2721, 0.2221, 0.2787, 0.2272]], grad_fn=<SoftmaxBackward0>), tensor([[-2.8159e-02, -3.6450e-02, -5.3179e-02,  2.6307e-01],\n",
      "        [-8.2034e-02, -2.8332e-02, -9.8023e-02,  5.1501e-02],\n",
      "        [ 1.2571e-01, -1.6694e-01,  2.2056e-01, -5.2026e-02],\n",
      "        [ 6.2877e-02,  2.0869e-02,  9.5487e-02,  2.1517e-02],\n",
      "        [-2.2551e-02, -4.1781e-03,  2.0026e-02,  1.9584e-01],\n",
      "        [ 3.3476e-03, -1.7130e-01,  1.0720e-01,  6.8158e-02],\n",
      "        [ 7.1804e-02,  1.1190e-02, -1.1092e-01,  1.4620e-01],\n",
      "        [-7.3048e-03, -1.0374e-01, -1.6774e-02, -3.1905e-02],\n",
      "        [ 5.1074e-02,  7.4200e-02, -3.0187e-02,  1.1672e-01],\n",
      "        [-1.5581e-04, -2.9015e-02, -1.7432e-01,  5.2159e-02]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0853, -0.0957, -0.2018, -0.2017],\n",
      "        [-0.0721,  0.1353, -0.1505,  0.0230],\n",
      "        [-0.0039, -0.1131,  0.0600,  0.0710],\n",
      "        [-0.0751, -0.0712, -0.0295, -0.0483],\n",
      "        [-0.2429,  0.1755,  0.0738,  0.1286],\n",
      "        [-0.1712, -0.0297,  0.0054,  0.1087],\n",
      "        [-0.0891,  0.0722, -0.0174, -0.2060],\n",
      "        [-0.1386, -0.0403,  0.0419, -0.0429],\n",
      "        [-0.0368,  0.0829, -0.0359, -0.0713],\n",
      "        [-0.1215,  0.0762,  0.0168,  0.0712]], grad_fn=<AddmmBackward0>))\n",
      "Real class: tensor([[1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2/57 [07:39<3:30:47, 229.96s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 14\u001B[0m\n\u001B[0;32m     12\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mSGD(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlearning_rate)\n\u001B[0;32m     13\u001B[0m scheduler \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mExponentialLR(optimizer, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.8\u001B[39m)\n\u001B[1;32m---> 14\u001B[0m \u001B[43mtrain_with_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer_to_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler_to_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscheduler\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[12], line 10\u001B[0m, in \u001B[0;36mtrain_with_metrics\u001B[1;34m(model_to_train, optimizer_to_train, scheduler_to_train)\u001B[0m\n\u001B[0;32m      8\u001B[0m model_to_train\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m=> Training epoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 10\u001B[0m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_to_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer_to_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler_to_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m=> Finished training...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     12\u001B[0m model_to_train\u001B[38;5;241m.\u001B[39meval()\n",
      "Cell \u001B[1;32mIn[10], line 5\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(loader, model_input, optimizer_input, loss_function, scheduler_input)\u001B[0m\n\u001B[0;32m      3\u001B[0m data, targets \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device), targets\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      4\u001B[0m optimizer_input\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m----> 5\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_function(predictions[\u001B[38;5;241m0\u001B[39m], targets)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Licenta\\Proiect\\model_aux.py:64\u001B[0m, in \u001B[0;36mGoogLeNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Tensor, Tensor, Tensor]:\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;66;03m# N x 3 x 224 x 224\u001B[39;00m\n\u001B[1;32m---> 64\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;66;03m# N x 64 x 112 x 112\u001B[39;00m\n\u001B[0;32m     66\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmaxpool1(x)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Licenta\\Proiect\\model_aux.py:179\u001B[0m, in \u001B[0;36mBasicConv2d.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 179\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    180\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn(x)\n\u001B[0;32m    181\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mrelu(x, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\_device.py:77\u001B[0m, in \u001B[0;36mDeviceContext.__torch_function__\u001B[1;34m(self, func, types, args, kwargs)\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m func \u001B[38;5;129;01min\u001B[39;00m _device_constructors() \u001B[38;5;129;01mand\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     76\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\n\u001B[1;32m---> 77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from model_aux import GoogLeNet\n",
    "\n",
    "model = GoogLeNet()\n",
    "\n",
    "#def get_batch_sizes():\n",
    "    #run = wandb.init(config=sweep_config)\n",
    "#bs = wandb.config.batch_sizes\n",
    "\n",
    "#wandb.agent(sweep_id, function=train_with_metrics, count=5)\n",
    "    #run.finish()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "train_with_metrics(model, optimizer_to_train=optimizer, scheduler_to_train=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#wandb.agent(sweep_id, function=get_batch_sizes, count=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
